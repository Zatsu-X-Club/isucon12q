.\" Automatically generated by Pod::Man 4.14 (Pod::Simple 3.42)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "PT-QUERY-DIGEST 1p"
.TH PT-QUERY-DIGEST 1p "2016-03-07" "perl v5.34.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
pt\-query\-digest \- Analyze MySQL queries from logs, processlist, and tcpdump.
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
Usage: pt-query-digest [\s-1OPTIONS\s0] [\s-1FILES\s0] [\s-1DSN\s0]
.PP
pt-query-digest analyzes MySQL queries from slow, general, and binary log
files.  It can also analyze queries from \f(CW\*(C`SHOW PROCESSLIST\*(C'\fR and MySQL
protocol data from tcpdump.  By default, queries are grouped by fingerprint
and reported in descending order of query time (i.e. the slowest queries
first).  If no \f(CW\*(C`FILES\*(C'\fR are given, the tool reads \f(CW\*(C`STDIN\*(C'\fR.  The optional
\&\f(CW\*(C`DSN\*(C'\fR is used for certain options like \*(L"\-\-since\*(R" and \*(L"\-\-until\*(R".
.PP
Report the slowest queries from \f(CW\*(C`slow.log\*(C'\fR:
.PP
.Vb 1
\&   pt\-query\-digest slow.log
.Ve
.PP
Report the slowest queries from the processlist on host1:
.PP
.Vb 1
\&   pt\-query\-digest \-\-processlist h=host1
.Ve
.PP
Capture MySQL protocol data with tcppdump, then report the slowest queries:
.PP
.Vb 1
\&   tcpdump \-s 65535 \-x \-nn \-q \-tttt \-i any \-c 1000 port 3306 > mysql.tcp.txt
\&
\&   pt\-query\-digest \-\-type tcpdump mysql.tcp.txt
.Ve
.PP
Save query data from \f(CW\*(C`slow.log\*(C'\fR to host2 for later review and trend analysis:
.PP
.Vb 1
\&   pt\-query\-digest \-\-review h=host2 \-\-no\-report slow.log
.Ve
.SH "RISKS"
.IX Header "RISKS"
Percona Toolkit is mature, proven in the real world, and well tested,
but all database tools can pose a risk to the system and the database
server.  Before using this tool, please:
.IP "\(bu" 4
Read the tool's documentation
.IP "\(bu" 4
Review the tool's known \*(L"\s-1BUGS\*(R"\s0
.IP "\(bu" 4
Test the tool on a non-production server
.IP "\(bu" 4
Backup your production server and verify the backups
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
pt-query-digest is a sophisticated but easy to use tool for analyzing
MySQL queries.  It can analyze queries from MySQL slow, general, and binary
logs. (Binary logs must first be converted to text, see \*(L"\-\-type\*(R").
It can also use \f(CW\*(C`SHOW PROCESSLIST\*(C'\fR and MySQL protocol data from tcpdump.
By default, the tool reports which queries are the slowest, and therefore
the most important to optimize.  More complex and custom-tailored reports
can be created by using options like \*(L"\-\-group\-by\*(R", \*(L"\-\-filter\*(R", and
\&\*(L"\-\-embedded\-attributes\*(R".
.PP
Query analysis is a best-practice that should be done frequently.  To
make this easier, pt-query-digest has two features: query review
(\*(L"\-\-review\*(R") and query history (\*(L"\-\-history\*(R").  When the \*(L"\-\-review\*(R"
option is used, all unique queries are saved to a database.  When the
tool is ran again with \*(L"\-\-review\*(R", queries marked as reviewed in
the database are not printed in the report.  This highlights new queries
that need to be reviewed.  When the \*(L"\-\-history\*(R" option is used,
query metrics (query time, lock time, etc.) for each unique query are
saved to database.  Each time the tool is ran with \*(L"\-\-history\*(R", the
more historical data is saved which can be used to trend and analyze
query performance over time.
.SH "ATTRIBUTES"
.IX Header "ATTRIBUTES"
pt-query-digest works on events, which are a collection of key-value pairs
called attributes.  You'll recognize most of the attributes right away:
\&\f(CW\*(C`Query_time\*(C'\fR, \f(CW\*(C`Lock_time\*(C'\fR, and so on.  You can just look at a slow log
and see them.  However, there are some that don't exist in the slow log,
and slow logs may actually include different kinds of attributes (for example,
you may have a server with the Percona patches).
.PP
See \*(L"\s-1ATTRIBUTES REFERENCE\*(R"\s0 near the end of this documentation for a list
of common and \*(L"\-\-type\*(R" specific attributes.  A familiarity with these
attributes is necessary for working with \*(L"\-\-filter\*(R",
\&\*(L"\-\-ignore\-attributes\*(R", and other attribute-related options.
.PP
With creative use of \*(L"\-\-filter\*(R", you can create new attributes derived
from existing attributes.  For example, to create an attribute called
\&\f(CW\*(C`Row_ratio\*(C'\fR for examining the ratio of \f(CW\*(C`Rows_sent\*(C'\fR to \f(CW\*(C`Rows_examined\*(C'\fR,
specify a filter like:
.PP
.Vb 1
\&  \-\-filter \*(Aq($event\->{Row_ratio} = $event\->{Rows_sent} / ($event\->{Rows_examined})) && 1\*(Aq
.Ve
.PP
The \f(CW\*(C`&& 1\*(C'\fR trick is needed to create a valid one-line syntax that is always
true, even if the assignment happens to evaluate false.  The new attribute will
automatically appears in the output:
.PP
.Vb 1
\&  # Row ratio        1.00    0.00      1    0.50      1    0.71    0.50
.Ve
.PP
Attributes created this way can be specified for \*(L"\-\-order\-by\*(R" or any
option that requires an attribute.
.SH "OUTPUT"
.IX Header "OUTPUT"
The default \*(L"\-\-output\*(R" is a query analysis report.  The \*(L"\-\-[no]report\*(R"
option controls whether or not this report is printed.  Sometimes you may
want to parse all the queries but suppress the report, for example when using
\&\*(L"\-\-review\*(R" or \*(L"\-\-history\*(R".
.PP
There is one paragraph for each class of query analyzed.  A \*(L"class\*(R" of queries
all have the same value for the \*(L"\-\-group\-by\*(R" attribute which is
\&\f(CW\*(C`fingerprint\*(C'\fR by default.  (See \*(L"\s-1ATTRIBUTES\*(R"\s0.)  A fingerprint is an
abstracted version of the query text with literals removed, whitespace
collapsed, and so forth.  The report is formatted so it's easy to paste into
emails without wrapping, and all non-query lines begin with a comment, so you
can save it to a .sql file and open it in your favorite syntax-highlighting
text editor.  There is a response-time profile at the beginning.
.PP
The output described here is controlled by \*(L"\-\-report\-format\*(R".
That option allows you to specify what to print and in what order.
The default output in the default order is described here.
.PP
The report, by default, begins with a paragraph about the entire analysis run
The information is very similar to what you'll see for each class of queries in
the log, but it doesn't have some information that would be too expensive to
keep globally for the analysis.  It also has some statistics about the code's
execution itself, such as the \s-1CPU\s0 and memory usage, the local date and time
of the run, and a list of input file read/parsed.
.PP
Following this is the response-time profile over the events.  This is a
highly summarized view of the unique events in the detailed query report
that follows.  It contains the following columns:
.PP
.Vb 9
\& Column        Meaning
\& ============  ==========================================================
\& Rank          The query\*(Aqs rank within the entire set of queries analyzed
\& Query ID      The query\*(Aqs fingerprint
\& Response time The total response time, and percentage of overall total
\& Calls         The number of times this query was executed
\& R/Call        The mean response time per execution
\& V/M           The Variance\-to\-mean ratio of response time
\& Item          The distilled query
.Ve
.PP
A final line whose rank is shown as \s-1MISC\s0 contains aggregate statistics on the
queries that were not included in the report, due to options such as
\&\*(L"\-\-limit\*(R" and \*(L"\-\-outliers\*(R".  For details on the variance-to-mean ratio,
please see http://en.wikipedia.org/wiki/Index_of_dispersion.
.PP
Next, the detailed query report is printed.  Each query appears in a paragraph.
Here is a sample, slightly reformatted so 'perldoc' will not wrap lines in a
terminal.  The following will all be one paragraph, but we'll break it up for
commentary.
.PP
.Vb 1
\& # Query 2: 0.01 QPS, 0.02x conc, ID 0xFDEA8D2993C9CAF3 at byte 160665
.Ve
.PP
This line identifies the sequential number of the query in the sort order
specified by \*(L"\-\-order\-by\*(R".  Then there's the queries per second, and the
approximate concurrency for this query (calculated as a function of the timespan
and total Query_time).  Next there's a query \s-1ID.\s0  This \s-1ID\s0 is a hex version of
the query's checksum in the database, if you're using \*(L"\-\-review\*(R".  You can
select the reviewed query's details from the database with a query like \f(CW\*(C`SELECT
\&.... WHERE checksum=0xFDEA8D2993C9CAF3\*(C'\fR.
.PP
If you are investigating the report and want to print out every sample of a
particular query, then the following \*(L"\-\-filter\*(R" may be helpful:
.PP
.Vb 5
\&   pt\-query\-digest slow.log           \e
\&      \-\-no\-report                     \e
\&      \-\-output slowlog                \e
\&      \-\-filter \*(Aq$event\->{fingerprint} \e
\&           && make_checksum($event\->{fingerprint}) eq "FDEA8D2993C9CAF3"\*(Aq
.Ve
.PP
Notice that you must remove the \f(CW\*(C`0x\*(C'\fR prefix from the checksum.
.PP
Finally, in case you want to find a sample of the query in the log file, there's
the byte offset where you can look.  (This is not always accurate, due to some
anomalies in the slow log format, but it's usually right.)  The position
refers to the worst sample, which we'll see more about below.
.PP
Next is the table of metrics about this class of queries.
.PP
.Vb 6
\& #           pct   total    min    max     avg     95%  stddev  median
\& # Count       0       2
\& # Exec time  13   1105s   552s   554s    553s    554s      2s    553s
\& # Lock time   0   216us   99us  117us   108us   117us    12us   108us
\& # Rows sent  20   6.26M  3.13M  3.13M   3.13M   3.13M   12.73   3.13M
\& # Rows exam   0   6.26M  3.13M  3.13M   3.13M   3.13M   12.73   3.13M
.Ve
.PP
The first line is column headers for the table.  The percentage is the percent
of the total for the whole analysis run, and the total is the actual value of
the specified metric.  For example, in this case we can see that the query
executed 2 times, which is 13% of the total number of queries in the file.  The
min, max and avg columns are self-explanatory.  The 95% column shows the 95th
percentile; 95% of the values are less than or equal to this value.  The
standard deviation shows you how tightly grouped the values are.  The standard
deviation and median are both calculated from the 95th percentile, discarding
the extremely large values.
.PP
The stddev, median and 95th percentile statistics are approximate.  Exact
statistics require keeping every value seen, sorting, and doing some
calculations on them.  This uses a lot of memory.  To avoid this, we keep 1000
buckets, each of them 5% bigger than the one before, ranging from .000001 up to
a very big number.  When we see a value we increment the bucket into which it
falls.  Thus we have fixed memory per class of queries.  The drawback is the
imprecision, which typically falls in the 5 percent range.
.PP
Next we have statistics on the users, databases and time range for the query.
.PP
.Vb 3
\& # Users       1   user1
\& # Databases   2     db1(1), db2(1)
\& # Time range 2008\-11\-26 04:55:18 to 2008\-11\-27 00:15:15
.Ve
.PP
The users and databases are shown as a count of distinct values, followed by the
values.  If there's only one, it's shown alone; if there are many, we show each
of the most frequent ones, followed by the number of times it appears.
.PP
.Vb 9
\& # Query_time distribution
\& #   1us
\& #  10us
\& # 100us
\& #   1ms
\& #  10ms  #####
\& # 100ms  ####################
\& #    1s  ##########
\& #  10s+
.Ve
.PP
The execution times show a logarithmic chart of time clustering.  Each query
goes into one of the \*(L"buckets\*(R" and is counted up.  The buckets are powers of
ten.  The first bucket is all values in the \*(L"single microsecond range\*(R" \*(-- that
is, less than 10us.  The second is \*(L"tens of microseconds,\*(R" which is from 10us
up to (but not including) 100us; and so on.  The charted attribute can be
changed by specifying \*(L"\-\-report\-histogram\*(R" but is limited to time-based
attributes.
.PP
.Vb 5
\& # Tables
\& #    SHOW TABLE STATUS LIKE \*(Aqtable1\*(Aq\eG
\& #    SHOW CREATE TABLE \`table1\`\eG
\& # EXPLAIN
\& SELECT * FROM table1\eG
.Ve
.PP
This section is a convenience: if you're trying to optimize the queries you see
in the slow log, you probably want to examine the table structure and size.
These are copy-and-paste-ready commands to do that.
.PP
Finally, we see a sample of the queries in this class of query.  This is not a
random sample.  It is the query that performed the worst, according to the sort
order given by \*(L"\-\-order\-by\*(R".  You will normally see a commented \f(CW\*(C`# EXPLAIN\*(C'\fR
line just before it, so you can copy-paste the query to examine its \s-1EXPLAIN\s0
plan. But for non-SELECT queries that isn't possible to do, so the tool tries to
transform the query into a roughly equivalent \s-1SELECT\s0 query, and adds that below.
.PP
If you want to find this sample event in the log, use the offset mentioned
above, and something like the following:
.PP
.Vb 1
\&  tail \-c +<offset> /path/to/file | head
.Ve
.PP
See also \*(L"\-\-report\-format\*(R".
.SH "QUERY REVIEW"
.IX Header "QUERY REVIEW"
A query \*(L"\-\-review\*(R" is the process of storing all the query fingerprints 
analyzed.  This has several benefits:
.IP "\(bu" 4
You can add metadata to classes of queries, such as marking them for follow-up,
adding notes to queries, or marking them with an issue \s-1ID\s0 for your issue
tracking system.
.IP "\(bu" 4
You can refer to the stored values on subsequent runs so you'll know whether
you've seen a query before.  This can help you cut down on duplicated work.
.IP "\(bu" 4
You can store historical data such as the row count, query times, and generally
anything you can see in the report.
.PP
To use this feature, you run pt-query-digest with the \*(L"\-\-review\*(R" option.  It
will store the fingerprints and other information into the table you specify.
Next time you run it with the same option, it will do the following:
.IP "\(bu" 4
It won't show you queries you've already reviewed.  A query is considered to be
already reviewed if you've set a value for the \f(CW\*(C`reviewed_by\*(C'\fR column.  (If you
want to see queries you've already reviewed, use the \*(L"\-\-report\-all\*(R" option.)
.IP "\(bu" 4
Queries that you've reviewed, and don't appear in the output, will cause gaps in
the query number sequence in the first line of each paragraph.  And the value
you've specified for \*(L"\-\-limit\*(R" will still be honored.  So if you've reviewed all
queries in the top 10 and you ask for the top 10, you won't see anything in the
output.
.IP "\(bu" 4
If you want to see the queries you've already reviewed, you can specify
\&\*(L"\-\-report\-all\*(R".  Then you'll see the normal analysis output, but you'll
also see the information from the review table, just below the execution time
graph.  For example,
.Sp
.Vb 8
\&  # Review information
\&  #      comments: really bad IN() subquery, fix soon!
\&  #    first_seen: 2008\-12\-01 11:48:57
\&  #   jira_ticket: 1933
\&  #     last_seen: 2008\-12\-18 11:49:07
\&  #      priority: high
\&  #   reviewed_by: xaprb
\&  #   reviewed_on: 2008\-12\-18 15:03:11
.Ve
.Sp
This metadata is useful because, as you analyze your queries, you get
your comments integrated right into the report.
.SH "FINGERPRINTS"
.IX Header "FINGERPRINTS"
A query fingerprint is the abstracted form of a query, which makes it possible
to group similar queries together.  Abstracting a query removes literal values,
normalizes whitespace, and so on.  For example, consider these two queries:
.PP
.Vb 3
\&  SELECT name, password FROM user WHERE id=\*(Aq12823\*(Aq;
\&  select name,   password from user
\&     where id=5;
.Ve
.PP
Both of those queries will fingerprint to
.PP
.Vb 1
\&  select name, password from user where id=?
.Ve
.PP
Once the query's fingerprint is known, we can then talk about a query as though
it represents all similar queries.
.PP
What \f(CW\*(C`pt\-query\-digest\*(C'\fR does is analogous to a \s-1GROUP BY\s0 statement in \s-1SQL.\s0  (But
note that \*(L"multiple columns\*(R" doesn't define a multi-column grouping; it defines
multiple reports!) If your command-line looks like this,
.PP
.Vb 5
\&  pt\-query\-digest               \e
\&      \-\-group\-by fingerprint    \e
\&      \-\-order\-by Query_time:sum \e
\&      \-\-limit 10                \e
\&      slow.log
.Ve
.PP
The corresponding pseudo-SQL looks like this:
.PP
.Vb 5
\&  SELECT WORST(query BY Query_time), SUM(Query_time), ...
\&  FROM /path/to/slow.log
\&  GROUP BY FINGERPRINT(query)
\&  ORDER BY SUM(Query_time) DESC
\&  LIMIT 10
.Ve
.PP
You can also use the value \f(CW\*(C`distill\*(C'\fR, which is a kind of super-fingerprint.
See \*(L"\-\-group\-by\*(R" for more.
.PP
Query fingerprinting accommodates many special cases, which have proven
necessary in the real world.  For example, an \f(CW\*(C`IN\*(C'\fR list with 5 literals
is really equivalent to one with 4 literals, so lists of literals are
collapsed to a single one.  If you find something that is not fingerprinted
properly, please submit a bug report with a reproducible test case.
.PP
Here is a list of transformations during fingerprinting, which might not
be exhaustive:
.IP "\(bu" 4
Group all \s-1SELECT\s0 queries from mysqldump together, even if they are against
different tables.  The same applies to all queries from pt-table-checksum.
.IP "\(bu" 4
Shorten multi-value \s-1INSERT\s0 statements to a single \s-1\fBVALUES\s0()\fR list.
.IP "\(bu" 4
Strip comments.
.IP "\(bu" 4
Abstract the databases in \s-1USE\s0 statements, so all \s-1USE\s0 statements are grouped
together.
.IP "\(bu" 4
Replace all literals, such as quoted strings.  For efficiency, the code that
replaces literal numbers is somewhat non-selective, and might replace some
things as numbers when they really are not.  Hexadecimal literals are also
replaced.  \s-1NULL\s0 is treated as a literal.  Numbers embedded in identifiers are
also replaced, so tables named similarly will be fingerprinted to the same
values (e.g. users_2009 and users_2010 will fingerprint identically).
.IP "\(bu" 4
Collapse all whitespace into a single space.
.IP "\(bu" 4
Lowercase the entire query.
.IP "\(bu" 4
Replace all literals inside of \s-1\fBIN\s0()\fR and \s-1\fBVALUES\s0()\fR lists with a single
placeholder, regardless of cardinality.
.IP "\(bu" 4
Collapse multiple identical \s-1UNION\s0 queries into a single one.
.SH "OPTIONS"
.IX Header "OPTIONS"
This tool accepts additional command-line arguments.  Refer to the
\&\*(L"\s-1SYNOPSIS\*(R"\s0 and usage information for details.
.IP "\-\-ask\-pass" 4
.IX Item "--ask-pass"
Prompt for a password when connecting to MySQL.
.IP "\-\-attribute\-aliases" 4
.IX Item "--attribute-aliases"
type: array; default: db|Schema
.Sp
List of attribute|alias,etc.
.Sp
Certain attributes have multiple names, like db and Schema.  If an event does
not have the primary attribute, pt-query-digest looks for an alias attribute.
If it finds an alias, it creates the primary attribute with the alias
attribute's value and removes the alias attribute.
.Sp
If the event has the primary attribute, all alias attributes are deleted.
.Sp
This helps simplify event attributes so that, for example, there will not
be report lines for both db and Schema.
.IP "\-\-attribute\-value\-limit" 4
.IX Item "--attribute-value-limit"
type: int; default: 4294967296
.Sp
A sanity limit for attribute values.
.Sp
This option deals with bugs in slow logging functionality that causes large
values for attributes.  If the attribute's value is bigger than this, the
last-seen value for that class of query is used instead.
The default is 4G (2^32). To disable (set no upper limit) set value to 0.
.IP "\-\-charset" 4
.IX Item "--charset"
short form: \-A; type: string
.Sp
Default character set.  If the value is utf8, sets Perl's binmode on
\&\s-1STDOUT\s0 to utf8, passes the mysql_enable_utf8 option to DBD::mysql, and
runs \s-1SET NAMES UTF8\s0 after connecting to MySQL.  Any other value sets
binmode on \s-1STDOUT\s0 without the utf8 layer, and runs \s-1SET NAMES\s0 after
connecting to MySQL.
.IP "\-\-config" 4
.IX Item "--config"
type: Array
.Sp
Read this comma-separated list of config files; if specified, this must be the
first option on the command line.
.IP "\-\-[no]continue\-on\-error" 4
.IX Item "--[no]continue-on-error"
default: yes
.Sp
Continue parsing even if there is an error.  The tool will not continue
forever: it stops once any process causes 100 errors, in which case there
is probably a bug in the tool or the input is invalid.
.IP "\-\-[no]create\-history\-table" 4
.IX Item "--[no]create-history-table"
default: yes
.Sp
Create the \*(L"\-\-history\*(R" table if it does not exist.
.Sp
This option causes the table specified by \*(L"\-\-history\*(R" to be created
with the default structure shown in the documentation for \*(L"\-\-history\*(R".
.IP "\-\-[no]create\-review\-table" 4
.IX Item "--[no]create-review-table"
default: yes
.Sp
Create the \*(L"\-\-review\*(R" table if it does not exist.
.Sp
This option causes the table specified by \*(L"\-\-review\*(R" to be created
with the default structure shown in the documentation for \*(L"\-\-review\*(R".
.IP "\-\-daemonize" 4
.IX Item "--daemonize"
Fork to the background and detach from the shell.  \s-1POSIX\s0
operating systems only.
.IP "\-\-database" 4
.IX Item "--database"
short form: \-D; type: string
.Sp
Connect to this database.
.IP "\-\-defaults\-file" 4
.IX Item "--defaults-file"
short form: \-F; type: string
.Sp
Only read mysql options from the given file.  You must give an absolute pathname.
.IP "\-\-embedded\-attributes" 4
.IX Item "--embedded-attributes"
type: array
.Sp
Two Perl regex patterns to capture pseudo-attributes embedded in queries.
.Sp
Embedded attributes might be special attribute-value pairs that you've hidden
in comments.  The first regex should match the entire set of attributes (in
case there are multiple).  The second regex should match and capture
attribute-value pairs from the first regex.
.Sp
For example, suppose your query looks like the following:
.Sp
.Vb 1
\&  SELECT * from users \-\- file: /login.php, line: 493;
.Ve
.Sp
You might run pt-query-digest with the following option:
.Sp
.Vb 1
\&  pt\-query\-digest \-\-embedded\-attributes \*(Aq \-\- .*\*(Aq,\*(Aq(\ew+): ([^\e,]+)\*(Aq
.Ve
.Sp
The first regular expression captures the whole comment:
.Sp
.Vb 1
\&  " \-\- file: /login.php, line: 493;"
.Ve
.Sp
The second one splits it into attribute-value pairs and adds them to the event:
.Sp
.Vb 4
\&   ATTRIBUTE  VALUE
\&   =========  ==========
\&   file       /login.php
\&   line       493
.Ve
.Sp
\&\fB\s-1NOTE\s0\fR: All commas in the regex patterns must be escaped with \e otherwise
the pattern will break.
.IP "\-\-expected\-range" 4
.IX Item "--expected-range"
type: array; default: 5,10
.Sp
Explain items when there are more or fewer than expected.
.Sp
Defines the number of items expected to be seen in the report given by
\&\*(L"\-\-[no]report\*(R", as controlled by \*(L"\-\-limit\*(R" and \*(L"\-\-outliers\*(R".  If
there  are more or fewer items in the report, each one will explain why it was
included.
.IP "\-\-explain" 4
.IX Item "--explain"
type: \s-1DSN\s0
.Sp
Run \s-1EXPLAIN\s0 for the sample query with this \s-1DSN\s0 and print results.
.Sp
This works only when \*(L"\-\-group\-by\*(R" includes fingerprint.  It causes
pt-query-digest to run \s-1EXPLAIN\s0 and include the output into the report.  For
safety, queries that appear to have a subquery that \s-1EXPLAIN\s0 will execute won't
be EXPLAINed.  Those are typically \*(L"derived table\*(R" queries of the form
.Sp
.Vb 1
\&  select ... from ( select .... ) der;
.Ve
.Sp
The \s-1EXPLAIN\s0 results are printed as a full vertical format in the event report,
which appears at the end of each event report in vertical style
(\f(CW\*(C`\eG\*(C'\fR) just like MySQL prints it.
.IP "\-\-filter" 4
.IX Item "--filter"
type: string
.Sp
Discard events for which this Perl code doesn't return true.
.Sp
This option is a string of Perl code or a file containing Perl code that gets
compiled into a subroutine with one argument: \f(CW$event\fR.  This is a hashref.
If the given value is a readable file, then pt-query-digest reads the entire
file and uses its contents as the code.  The file should not contain
a shebang (#!/usr/bin/perl) line.
.Sp
If the code returns true, the chain of callbacks continues; otherwise it ends.
The code is the last statement in the subroutine other than \f(CW\*(C`return $event\*(C'\fR. 
The subroutine template is:
.Sp
.Vb 1
\&  sub { $event = shift; filter && return $event; }
.Ve
.Sp
Filters given on the command line are wrapped inside parentheses like like
\&\f(CW\*(C`( filter )\*(C'\fR.  For complex, multi-line filters, you must put the code inside
a file so it will not be wrapped inside parentheses.  Either way, the filter
must produce syntactically valid code given the template.  For example, an
if-else branch given on the command line would not be valid:
.Sp
.Vb 1
\&  \-\-filter \*(Aqif () { } else { }\*(Aq  # WRONG
.Ve
.Sp
Since it's given on the command line, the if-else branch would be wrapped inside
parentheses which is not syntactically valid.  So to accomplish something more
complex like this would require putting the code in a file, for example
filter.txt:
.Sp
.Vb 1
\&  my $event_ok; if (...) { $event_ok=1; } else { $event_ok=0; } $event_ok
.Ve
.Sp
Then specify \f(CW\*(C`\-\-filter filter.txt\*(C'\fR to read the code from filter.txt.
.Sp
If the filter code won't compile, pt-query-digest will die with an error.
If the filter code does compile, an error may still occur at runtime if the
code tries to do something wrong (like pattern match an undefined value).
pt-query-digest does not provide any safeguards so code carefully!
.Sp
An example filter that discards everything but \s-1SELECT\s0 statements:
.Sp
.Vb 1
\&  \-\-filter \*(Aq$event\->{arg} =~ m/^select/i\*(Aq
.Ve
.Sp
This is compiled into a subroutine like the following:
.Sp
.Vb 1
\&  sub { $event = shift; ( $event\->{arg} =~ m/^select/i ) && return $event; }
.Ve
.Sp
It is permissible for the code to have side effects (to alter \f(CW$event\fR).
.Sp
See \*(L"\s-1ATTRIBUTES REFERENCE\*(R"\s0 for a list of common and \*(L"\-\-type\*(R" specific
attributes.
.Sp
Here are more examples of filter code:
.RS 4
.IP "Host/IP matches domain.com" 4
.IX Item "Host/IP matches domain.com"
\&\-\-filter '($event\->{host} || \f(CW$event\fR\->{ip} || "") =~ m/domain.com/'
.Sp
Sometimes MySQL logs the host where the \s-1IP\s0 is expected.  Therefore, we
check both.
.IP "User matches john" 4
.IX Item "User matches john"
\&\-\-filter '($event\->{user} || "") =~ m/john/'
.IP "More than 1 warning" 4
.IX Item "More than 1 warning"
\&\-\-filter '($event\->{Warning_count} || 0) > 1'
.IP "Query does full table scan or full join" 4
.IX Item "Query does full table scan or full join"
\&\-\-filter '(($event\->{Full_scan} || "\*(L") eq \*(R"Yes\*(L") || (($event\->{Full_join} || \*(R"\*(L") eq \*(R"Yes")'
.IP "Query was not served from query cache" 4
.IX Item "Query was not served from query cache"
\&\-\-filter '($event\->{QC_Hit} || "\*(L") eq \*(R"No"'
.IP "Query is 1 \s-1MB\s0 or larger" 4
.IX Item "Query is 1 MB or larger"
\&\-\-filter '$event\->{bytes} >= 1_048_576'
.RE
.RS 4
.Sp
Since \*(L"\-\-filter\*(R" allows you to alter \f(CW$event\fR, you can use it to do other
things, like create new attributes.  See \*(L"\s-1ATTRIBUTES\*(R"\s0 for an example.
.RE
.IP "\-\-group\-by" 4
.IX Item "--group-by"
type: Array; default: fingerprint
.Sp
Which attribute of the events to group by.
.Sp
In general, you can group queries into classes based on any attribute of the
query, such as \f(CW\*(C`user\*(C'\fR or \f(CW\*(C`db\*(C'\fR, which will by default show you which users
and which databases get the most \f(CW\*(C`Query_time\*(C'\fR.  The default attribute,
\&\f(CW\*(C`fingerprint\*(C'\fR, groups similar, abstracted queries into classes; see below
and see also \*(L"\s-1FINGERPRINTS\*(R"\s0.
.Sp
A report is printed for each \*(L"\-\-group\-by\*(R" value (unless \f(CW\*(C`\-\-no\-report\*(C'\fR is
given).  Therefore, \f(CW\*(C`\-\-group\-by user,db\*(C'\fR means \*(L"report on queries with the
same user and report on queries with the same db\*(R"; it does not mean \*(L"report
on queries with the same user and db.\*(R"  See also \*(L"\s-1OUTPUT\*(R"\s0.
.Sp
Every value must have a corresponding value in the same position in
\&\*(L"\-\-order\-by\*(R".  However, adding values to \*(L"\-\-group\-by\*(R" will automatically
add values to \*(L"\-\-order\-by\*(R", for your convenience.
.Sp
There are several magical values that cause some extra data mining to happen
before the grouping takes place:
.RS 4
.IP "fingerprint" 4
.IX Item "fingerprint"
This causes events to be fingerprinted to abstract queries into
a canonical form, which is then used to group events together into a class.
See \*(L"\s-1FINGERPRINTS\*(R"\s0 for more about fingerprinting.
.IP "tables" 4
.IX Item "tables"
This causes events to be inspected for what appear to be tables, and
then aggregated by that.  Note that a query that contains two or more tables
will be counted as many times as there are tables; so a join against two tables
will count the Query_time against both tables.
.IP "distill" 4
.IX Item "distill"
This is a sort of super-fingerprint that collapses queries down
into a suggestion of what they do, such as \f(CW\*(C`INSERT SELECT table1 table2\*(C'\fR.
.RE
.RS 4
.RE
.IP "\-\-help" 4
.IX Item "--help"
Show help and exit.
.IP "\-\-history" 4
.IX Item "--history"
type: \s-1DSN\s0
.Sp
Save metrics for each query class in the given table.  pt-query-digest saves
query metrics (query time, lock time, etc.) to this table so you can see how
query classes change over time.
.Sp
The default table is \f(CW\*(C`percona_schema.query_history\*(C'\fR.  Specify database
(D) and table (t) \s-1DSN\s0 options to override the default.  The database and
table are automatically created unless \f(CW\*(C`\-\-no\-create\-history\-table\*(C'\fR
is specified (see \*(L"\-\-[no]create\-history\-table\*(R").
.Sp
pt-query-digest inspects the columns in the table.  The table must have at
least the following columns:
.Sp
.Vb 4
\&  CREATE TABLE query_review_history (
\&    checksum     BIGINT UNSIGNED NOT NULL,
\&    sample       TEXT NOT NULL
\&  );
.Ve
.Sp
Any columns not mentioned above are inspected to see if they follow a certain
naming convention.  The column is special if the name ends with an underscore
followed by any of these values:
.Sp
.Vb 1
\&  pct|avg|cnt|sum|min|max|pct_95|stddev|median|rank
.Ve
.Sp
If the column ends with one of those values, then the prefix is interpreted as
the event attribute to store in that column, and the suffix is interpreted as
the metric to be stored.  For example, a column named \f(CW\*(C`Query_time_min\*(C'\fR will be
used to store the minimum \f(CW\*(C`Query_time\*(C'\fR for the class of events.
.Sp
The table should also have a primary key, but that is up to you, depending on
how you want to store the historical data.  We suggest adding ts_min and ts_max
columns and making them part of the primary key along with the checksum.  But
you could also just add a ts_min column and make it a \s-1DATE\s0 type, so you'd get
one row per class of queries per day.
.Sp
The following table definition is used for \*(L"\-\-[no]create\-history\-table\*(R":
.Sp
.Vb 10
\& CREATE TABLE IF NOT EXISTS query_history (
\&   checksum             BIGINT UNSIGNED NOT NULL,
\&   sample               TEXT NOT NULL,
\&   ts_min               DATETIME,
\&   ts_max               DATETIME,
\&   ts_cnt               FLOAT,
\&   Query_time_sum       FLOAT,
\&   Query_time_min       FLOAT,
\&   Query_time_max       FLOAT,
\&   Query_time_pct_95    FLOAT,
\&   Query_time_stddev    FLOAT,
\&   Query_time_median    FLOAT,
\&   Lock_time_sum        FLOAT,
\&   Lock_time_min        FLOAT,
\&   Lock_time_max        FLOAT,
\&   Lock_time_pct_95     FLOAT,
\&   Lock_time_stddev     FLOAT,
\&   Lock_time_median     FLOAT,
\&   Rows_sent_sum        FLOAT,
\&   Rows_sent_min        FLOAT,
\&   Rows_sent_max        FLOAT,
\&   Rows_sent_pct_95     FLOAT,
\&   Rows_sent_stddev     FLOAT,
\&   Rows_sent_median     FLOAT,
\&   Rows_examined_sum    FLOAT,
\&   Rows_examined_min    FLOAT,
\&   Rows_examined_max    FLOAT,
\&   Rows_examined_pct_95 FLOAT,
\&   Rows_examined_stddev FLOAT,
\&   Rows_examined_median FLOAT,
\&   \-\- Percona extended slowlog attributes 
\&   \-\- http://www.percona.com/docs/wiki/patches:slow_extended
\&   Rows_affected_sum             FLOAT,
\&   Rows_affected_min             FLOAT,
\&   Rows_affected_max             FLOAT,
\&   Rows_affected_pct_95          FLOAT,
\&   Rows_affected_stddev          FLOAT,
\&   Rows_affected_median          FLOAT,
\&   Rows_read_sum                 FLOAT,
\&   Rows_read_min                 FLOAT,
\&   Rows_read_max                 FLOAT,
\&   Rows_read_pct_95              FLOAT,
\&   Rows_read_stddev              FLOAT,
\&   Rows_read_median              FLOAT,
\&   Merge_passes_sum              FLOAT,
\&   Merge_passes_min              FLOAT,
\&   Merge_passes_max              FLOAT,
\&   Merge_passes_pct_95           FLOAT,
\&   Merge_passes_stddev           FLOAT,
\&   Merge_passes_median           FLOAT,
\&   InnoDB_IO_r_ops_min           FLOAT,
\&   InnoDB_IO_r_ops_max           FLOAT,
\&   InnoDB_IO_r_ops_pct_95        FLOAT,
\&   InnoDB_IO_r_ops_stddev        FLOAT,
\&   InnoDB_IO_r_ops_median        FLOAT,
\&   InnoDB_IO_r_bytes_min         FLOAT,
\&   InnoDB_IO_r_bytes_max         FLOAT,
\&   InnoDB_IO_r_bytes_pct_95      FLOAT,
\&   InnoDB_IO_r_bytes_stddev      FLOAT,
\&   InnoDB_IO_r_bytes_median      FLOAT,
\&   InnoDB_IO_r_wait_min          FLOAT,
\&   InnoDB_IO_r_wait_max          FLOAT,
\&   InnoDB_IO_r_wait_pct_95       FLOAT,
\&   InnoDB_IO_r_wait_stddev       FLOAT,
\&   InnoDB_IO_r_wait_median       FLOAT,
\&   InnoDB_rec_lock_wait_min      FLOAT,
\&   InnoDB_rec_lock_wait_max      FLOAT,
\&   InnoDB_rec_lock_wait_pct_95   FLOAT,
\&   InnoDB_rec_lock_wait_stddev   FLOAT,
\&   InnoDB_rec_lock_wait_median   FLOAT,
\&   InnoDB_queue_wait_min         FLOAT,
\&   InnoDB_queue_wait_max         FLOAT,
\&   InnoDB_queue_wait_pct_95      FLOAT,
\&   InnoDB_queue_wait_stddev      FLOAT,
\&   InnoDB_queue_wait_median      FLOAT,
\&   InnoDB_pages_distinct_min     FLOAT,
\&   InnoDB_pages_distinct_max     FLOAT,
\&   InnoDB_pages_distinct_pct_95  FLOAT,
\&   InnoDB_pages_distinct_stddev  FLOAT,
\&   InnoDB_pages_distinct_median  FLOAT,
\&   \-\- Boolean (Yes/No) attributes.  Only the cnt and sum are needed
\&   \-\- for these.  cnt is how many times is attribute was recorded,
\&   \-\- and sum is how many of those times the value was Yes.  So
\&   \-\- sum/cnt * 100 equals the percentage of recorded times that
\&   \-\- the value was Yes.
\&   QC_Hit_cnt          FLOAT,
\&   QC_Hit_sum          FLOAT,
\&   Full_scan_cnt       FLOAT,
\&   Full_scan_sum       FLOAT,
\&   Full_join_cnt       FLOAT,
\&   Full_join_sum       FLOAT,
\&   Tmp_table_cnt       FLOAT,
\&   Tmp_table_sum       FLOAT,
\&   Tmp_table_on_disk_cnt FLOAT,
\&   Tmp_table_on_disk_sum FLOAT,
\&   Filesort_cnt          FLOAT,
\&   Filesort_sum          FLOAT,
\&   Filesort_on_disk_cnt  FLOAT,
\&   Filesort_on_disk_sum  FLOAT,
\&   PRIMARY KEY(checksum, ts_min, ts_max)
\& );
.Ve
.Sp
Note that we store the count (cnt) for the ts attribute only; it will be
redundant to store this for other attributes.
.IP "\-\-host" 4
.IX Item "--host"
short form: \-h; type: string
.Sp
Connect to host.
.IP "\-\-ignore\-attributes" 4
.IX Item "--ignore-attributes"
type: array; default: arg, cmd, insert_id, ip, port, Thread_id, timestamp, exptime, flags, key, res, val, server_id, offset, end_log_pos, Xid
.Sp
Do not aggregate these attributes.  Some attributes are not query metrics
but metadata which doesn't need to be (or can't be) aggregated.
.IP "\-\-inherit\-attributes" 4
.IX Item "--inherit-attributes"
type: array; default: db,ts
.Sp
If missing, inherit these attributes from the last event that had them.
.Sp
This option sets which attributes are inherited or carried forward to events
which do not have them.  For example, if one event has the db attribute equal
to \*(L"foo\*(R", but the next event doesn't have the db attribute, then it inherits
\&\*(L"foo\*(R" for its db attribute.
.IP "\-\-interval" 4
.IX Item "--interval"
type: float; default: .1
.Sp
How frequently to poll the processlist, in seconds.
.IP "\-\-iterations" 4
.IX Item "--iterations"
type: int; default: 1
.Sp
How many times to iterate through the collect-and-report cycle.  If 0, iterate
to infinity.  Each iteration runs for \*(L"\-\-run\-time\*(R" amount of time.  An
iteration is usually determined by an amount of time and a report is printed
when that amount of time elapses.  With \*(L"\-\-run\-time\-mode\*(R" \f(CW\*(C`interval\*(C'\fR,
an interval is instead determined by the interval time you specify with
\&\*(L"\-\-run\-time\*(R".  See \*(L"\-\-run\-time\*(R" and \*(L"\-\-run\-time\-mode\*(R" for more
information.
.IP "\-\-limit" 4
.IX Item "--limit"
type: Array; default: 95%:20
.Sp
Limit output to the given percentage or count.
.Sp
If the argument is an integer, report only the top N worst queries.  If the
argument is an integer followed by the \f(CW\*(C`%\*(C'\fR sign, report that percentage of the
worst queries.  If the percentage is followed by a colon and another integer,
report the top percentage or the number specified by that integer, whichever
comes first.
.Sp
The value is actually a comma-separated array of values, one for each item in
\&\*(L"\-\-group\-by\*(R".  If you don't specify a value for any of those items, the
default is the top 95%.
.Sp
See also \*(L"\-\-outliers\*(R".
.IP "\-\-log" 4
.IX Item "--log"
type: string
.Sp
Print all output to this file when daemonized.
.IP "\-\-order\-by" 4
.IX Item "--order-by"
type: Array; default: Query_time:sum
.Sp
Sort events by this attribute and aggregate function.
.Sp
This is a comma-separated list of order-by expressions, one for each
\&\*(L"\-\-group\-by\*(R" attribute.  The default \f(CW\*(C`Query_time:sum\*(C'\fR is used for
\&\*(L"\-\-group\-by\*(R" attributes without explicitly given \*(L"\-\-order\-by\*(R" attributes
(that is, if you specify more \*(L"\-\-group\-by\*(R" attributes than corresponding
\&\*(L"\-\-order\-by\*(R" attributes).  The syntax is \f(CW\*(C`attribute:aggregate\*(C'\fR.  See
\&\*(L"\s-1ATTRIBUTES\*(R"\s0 for valid attributes.  Valid aggregates are:
.Sp
.Vb 6
\&   Aggregate Meaning
\&   ========= ============================
\&   sum       Sum/total attribute value
\&   min       Minimum attribute value
\&   max       Maximum attribute value
\&   cnt       Frequency/count of the query
.Ve
.Sp
For example, the default \f(CW\*(C`Query_time:sum\*(C'\fR means that queries in the
query analysis report will be ordered (sorted) by their total query execution
time (\*(L"Exec time\*(R").  \f(CW\*(C`Query_time:max\*(C'\fR orders the queries by their
maximum query execution time, so the query with the single largest
\&\f(CW\*(C`Query_time\*(C'\fR will be list first.  \f(CW\*(C`cnt\*(C'\fR refers more to the frequency
of the query as a whole, how often it appears; \*(L"Count\*(R" is its corresponding
line in the query analysis report.  So any attribute and \f(CW\*(C`cnt\*(C'\fR should yield
the same report wherein queries are sorted by the number of times they
appear.
.Sp
When parsing general logs (\*(L"\-\-type\*(R" \f(CW\*(C`genlog\*(C'\fR), the default \*(L"\-\-order\-by\*(R"
becomes \f(CW\*(C`Query_time:cnt\*(C'\fR.  General logs do not report query times so only
the \f(CW\*(C`cnt\*(C'\fR aggregate makes sense because all query times are zero.
.Sp
If you specify an attribute that doesn't exist in the events, then
pt-query-digest falls back to the default \f(CW\*(C`Query_time:sum\*(C'\fR and prints a notice
at the beginning of the report for each query class.  You can create attributes
with \*(L"\-\-filter\*(R" and order by them; see \*(L"\s-1ATTRIBUTES\*(R"\s0 for an example.
.IP "\-\-outliers" 4
.IX Item "--outliers"
type: array; default: Query_time:1:10
.Sp
Report outliers by attribute:percentile:count.
.Sp
The syntax of this option is a comma-separated list of colon-delimited strings.
The first field is the attribute by which an outlier is defined.  The second is
a number that is compared to the attribute's 95th percentile.  The third is
optional, and is compared to the attribute's cnt aggregate.  Queries that pass
this specification are added to the report, regardless of any limits you
specified in \*(L"\-\-limit\*(R".
.Sp
For example, to report queries whose 95th percentile Query_time is at least 60
seconds and which are seen at least 5 times, use the following argument:
.Sp
.Vb 1
\&  \-\-outliers Query_time:60:5
.Ve
.Sp
You can specify an \-\-outliers option for each value in \*(L"\-\-group\-by\*(R".
.IP "\-\-output" 4
.IX Item "--output"
type: string; default: report
.Sp
How to format and print the query analysis results.  Accepted values are:
.Sp
.Vb 6
\&   VALUE      FORMAT
\&   =======    ==============================
\&   report     Standard query analysis report
\&   slowlog    MySQL slow log
\&   json       JSON, on array per query class
\&   json\-anon  JSON without example queries
.Ve
.Sp
The entire \f(CW\*(C`report\*(C'\fR output can be disabled by specifying \f(CW\*(C`\-\-no\-report\*(C'\fR
(see \*(L"\-\-[no]report\*(R"), and its sections can be disabled or rearranged
by specifying \*(L"\-\-report\-format\*(R".
.Sp
\&\f(CW\*(C`json\*(C'\fR output was introduced in 2.2.1 and is still in development,
so the data structure may change in future versions.
.IP "\-\-password" 4
.IX Item "--password"
short form: \-p; type: string
.Sp
Password to use when connecting.
If password contains commas they must be escaped with a backslash: \*(L"exam\e,ple\*(R"
.IP "\-\-pid" 4
.IX Item "--pid"
type: string
.Sp
Create the given \s-1PID\s0 file.  The tool won't start if the \s-1PID\s0 file already
exists and the \s-1PID\s0 it contains is different than the current \s-1PID.\s0  However,
if the \s-1PID\s0 file exists and the \s-1PID\s0 it contains is no longer running, the
tool will overwrite the \s-1PID\s0 file with the current \s-1PID.\s0  The \s-1PID\s0 file is
removed automatically when the tool exits.
.IP "\-\-port" 4
.IX Item "--port"
short form: \-P; type: int
.Sp
Port number to use for connection.
.IP "\-\-processlist" 4
.IX Item "--processlist"
type: \s-1DSN\s0
.Sp
Poll this \s-1DSN\s0's processlist for queries, with \*(L"\-\-interval\*(R" sleep between.
.Sp
If the connection fails, pt-query-digest tries to reopen it once per second.
.IP "\-\-progress" 4
.IX Item "--progress"
type: array; default: time,30
.Sp
Print progress reports to \s-1STDERR.\s0  The value is a comma-separated list with two
parts.  The first part can be percentage, time, or iterations; the second part
specifies how often an update should be printed, in percentage, seconds, or
number of iterations.
.IP "\-\-read\-timeout" 4
.IX Item "--read-timeout"
type: time; default: 0
.Sp
Wait this long for an event from the input; 0 to wait forever.
.Sp
This option sets the maximum time to wait for an event from the input.  It
applies to all types of input except \*(L"\-\-processlist\*(R".  If an
event is not received after the specified time, the script stops reading the
input and prints its reports.  If \*(L"\-\-iterations\*(R" is 0 or greater than
1, the next iteration will begin, else the script will exit.
.Sp
This option requires the Perl \s-1POSIX\s0 module.
.IP "\-\-[no]report" 4
.IX Item "--[no]report"
default: yes
.Sp
Print query analysis reports for each \*(L"\-\-group\-by\*(R" attribute.  This is
the standard slow log analysis functionality.  See \*(L"\s-1OUTPUT\*(R"\s0 for the
description of what this does and what the results look like.
.Sp
If you don't need a report (for example, when using \*(L"\-\-review\*(R" or
\&\*(L"\-\-history\*(R"), it is best to specify \f(CW\*(C`\-\-no\-report\*(C'\fR because this allows
the tool to skip some expensive operations.
.IP "\-\-report\-all" 4
.IX Item "--report-all"
Report all queries, even ones that have been reviewed.  This only affects
the \f(CW\*(C`report\*(C'\fR \*(L"\-\-output\*(R" when using \*(L"\-\-review\*(R".  Otherwise, all
queries are always printed.
.IP "\-\-report\-format" 4
.IX Item "--report-format"
type: Array; default: rusage,date,hostname,files,header,profile,query_report,prepared
.Sp
Print these sections of the query analysis report.
.Sp
.Vb 10
\&  SECTION      PRINTS
\&  ============ ======================================================
\&  rusage       CPU times and memory usage reported by ps
\&  date         Current local date and time
\&  hostname     Hostname of machine on which pt\-query\-digest was run
\&  files        Input files read/parse
\&  header       Summary of the entire analysis run
\&  profile      Compact table of queries for an overview of the report
\&  query_report Detailed information about each unique query
\&  prepared     Prepared statements
.Ve
.Sp
The sections are printed in the order specified.  The rusage, date, files and
header sections are grouped together if specified together; other sections are
separated by blank lines.
.Sp
See \*(L"\s-1OUTPUT\*(R"\s0 for more information on the various parts of the query report.
.IP "\-\-report\-histogram" 4
.IX Item "--report-histogram"
type: string; default: Query_time
.Sp
Chart the distribution of this attribute's values.
.Sp
The distribution chart is limited to time-based attributes, so charting
\&\f(CW\*(C`Rows_examined\*(C'\fR, for example, will produce a useless chart.  Charts look
like:
.Sp
.Vb 9
\&  # Query_time distribution
\&  #   1us
\&  #  10us
\&  # 100us
\&  #   1ms
\&  #  10ms  ###########################
\&  # 100ms  ########################################################
\&  #    1s  ########
\&  #  10s+
.Ve
.Sp
See \*(L"\s-1OUTPUT\*(R"\s0 for more information.
.IP "\-\-resume" 4
.IX Item "--resume"
type: string
.Sp
If specified, the tool writes the last file offset, if there is one,
to the given filename. When ran again with the same value for this option,
the tool reads the last file offset from the file, seeks to that position
in the log, and resumes parsing events from that point onward.
.IP "\-\-review" 4
.IX Item "--review"
type: \s-1DSN\s0
.Sp
Save query classes for later review, and don't report already reviewed classes.
.Sp
The default table is \f(CW\*(C`percona_schema.query_review\*(C'\fR.  Specify database
(D) and table (t) \s-1DSN\s0 options to override the default.  The database and
table are automatically created unless \f(CW\*(C`\-\-no\-create\-review\-table\*(C'\fR
is specified (see \*(L"\-\-[no]create\-review\-table\*(R").
.Sp
If the table was created manually, it must have at least the following columns.
You can add more columns for your own special purposes, but they won't be used
by pt-query-digest.
.Sp
.Vb 10
\&  CREATE TABLE IF NOT EXISTS query_review (
\&     checksum     BIGINT UNSIGNED NOT NULL PRIMARY KEY,
\&     fingerprint  TEXT NOT NULL,
\&     sample       TEXT NOT NULL,
\&     first_seen   DATETIME,
\&     last_seen    DATETIME,
\&     reviewed_by  VARCHAR(20),
\&     reviewed_on  DATETIME,
\&     comments     TEXT
\&  )
.Ve
.Sp
The columns are:
.Sp
.Vb 10
\&  COLUMN       MEANING
\&  ===========  ====================================================
\&  checksum     A 64\-bit checksum of the query fingerprint
\&  fingerprint  The abstracted version of the query; its primary key
\&  sample       The query text of a sample of the class of queries
\&  first_seen   The smallest timestamp of this class of queries
\&  last_seen    The largest timestamp of this class of queries
\&  reviewed_by  Initially NULL; if set, query is skipped thereafter
\&  reviewed_on  Initially NULL; not assigned any special meaning
\&  comments     Initially NULL; not assigned any special meaning
.Ve
.Sp
Note that the \f(CW\*(C`fingerprint\*(C'\fR column is the true primary key for a class of
queries.  The \f(CW\*(C`checksum\*(C'\fR is just a cryptographic hash of this value, which
provides a shorter value that is very likely to also be unique.
.Sp
After parsing and aggregating events, your table should contain a row for each
fingerprint.  This option depends on \f(CW\*(C`\-\-group\-by fingerprint\*(C'\fR (which is the
default).  It will not work otherwise.
.IP "\-\-run\-time" 4
.IX Item "--run-time"
type: time
.Sp
How long to run for each \*(L"\-\-iterations\*(R".  The default is to run forever
(you can interrupt with CTRL-C).  Because \*(L"\-\-iterations\*(R" defaults to 1,
if you only specify \*(L"\-\-run\-time\*(R", pt-query-digest runs for that amount of
time and then exits.  The two options are specified together to do
collect-and-report cycles.  For example, specifying \*(L"\-\-iterations\*(R" \f(CW4\fR
\&\*(L"\-\-run\-time\*(R" \f(CW\*(C`15m\*(C'\fR with a continuous input (like \s-1STDIN\s0 or
\&\*(L"\-\-processlist\*(R") will cause pt-query-digest to run for 1 hour
(15 minutes x 4), reporting four times, once at each 15 minute interval.
.IP "\-\-run\-time\-mode" 4
.IX Item "--run-time-mode"
type: string; default: clock
.Sp
Set what the value of \*(L"\-\-run\-time\*(R" operates on.  Following are the possible
values for this option:
.RS 4
.IP "clock" 4
.IX Item "clock"
\&\*(L"\-\-run\-time\*(R" specifies an amount of real clock time during which the tool
should run for each \*(L"\-\-iterations\*(R".
.IP "event" 4
.IX Item "event"
\&\*(L"\-\-run\-time\*(R" specifies an amount of log time.  Log time is determined by
timestamps in the log.  The first timestamp seen is remembered, and each
timestamp after that is compared to the first to determine how much log time
has passed.  For example, if the first timestamp seen is \f(CW\*(C`12:00:00\*(C'\fR and the
next is \f(CW\*(C`12:01:30\*(C'\fR, that is 1 minute and 30 seconds of log time.  The tool
will read events until the log time is greater than or equal to the specified
\&\*(L"\-\-run\-time\*(R" value.
.Sp
Since timestamps in logs are not always printed, or not always printed
frequently, this mode varies in accuracy.
.IP "interval" 4
.IX Item "interval"
\&\*(L"\-\-run\-time\*(R" specifies interval boundaries of log time into which events
are divided and reports are generated.  This mode is different from the
others because it doesn't specify how long to run.  The value of
\&\*(L"\-\-run\-time\*(R" must be an interval that divides evenly into minutes, hours
or days.  For example, \f(CW\*(C`5m\*(C'\fR divides evenly into hours (60/5=12, so 12
5 minutes intervals per hour) but \f(CW\*(C`7m\*(C'\fR does not (60/7=8.6).
.Sp
Specifying \f(CW\*(C`\-\-run\-time\-mode interval \-\-run\-time 30m \-\-iterations 0\*(C'\fR is
similar to specifying \f(CW\*(C`\-\-run\-time\-mode clock \-\-run\-time 30m \-\-iterations 0\*(C'\fR.
In the latter case, pt-query-digest will run forever, producing reports every
30 minutes, but this only works effectively with  continuous inputs like
\&\s-1STDIN\s0 and the processlist.  For fixed inputs, like log files, the former
example produces multiple reports by dividing the log into 30 minutes
intervals based on timestamps.
.Sp
Intervals are calculated from the zeroth second/minute/hour in which a
timestamp occurs, not from whatever time it specifies.  For example,
with 30 minute intervals and a timestamp of \f(CW\*(C`12:10:30\*(C'\fR, the interval
is \fInot\fR \f(CW\*(C`12:10:30\*(C'\fR to \f(CW\*(C`12:40:30\*(C'\fR, it is \f(CW\*(C`12:00:00\*(C'\fR to \f(CW\*(C`12:29:59\*(C'\fR.
Or, with 1 hour intervals, it is \f(CW\*(C`12:00:00\*(C'\fR to \f(CW\*(C`12:59:59\*(C'\fR.
When a new timestamp exceeds the interval, a report is printed, and the
next interval is recalculated based on the new timestamp.
.Sp
Since \*(L"\-\-iterations\*(R" is 1 by default, you probably want to specify
a new value else pt-query-digest will only get and report on the first
interval from the log since 1 interval = 1 iteration.  If you want to
get and report every interval in a log, specify \*(L"\-\-iterations\*(R" \f(CW0\fR.
.RE
.RS 4
.RE
.IP "\-\-sample" 4
.IX Item "--sample"
type: int
.Sp
Filter out all but the first N occurrences of each query.  The queries are
filtered on the first value in \*(L"\-\-group\-by\*(R", so by default, this will filter
by query fingerprint.  For example, \f(CW\*(C`\-\-sample 2\*(C'\fR will permit two sample queries
for each fingerprint.  Useful in conjunction with \f(CW\*(C`\-\-output slowlog\*(C'\fR to print
the queries.  You probably want to set \f(CW\*(C`\-\-no\-report\*(C'\fR to avoid the overhead of
aggregating and reporting if you're just using this to print out samples of
queries.  A complete example:
.Sp
.Vb 1
\&  pt\-query\-digest \-\-sample 2 \-\-no\-report \-\-output slowlog slow.log
.Ve
.IP "\-\-set\-vars" 4
.IX Item "--set-vars"
type: Array
.Sp
Set the MySQL variables in this comma-separated list of \f(CW\*(C`variable=value\*(C'\fR pairs.
.Sp
By default, the tool sets:
.Sp
.Vb 1
\&   wait_timeout=10000
.Ve
.Sp
Variables specified on the command line override these defaults.  For
example, specifying \f(CW\*(C`\-\-set\-vars wait_timeout=500\*(C'\fR overrides the defaultvalue of \f(CW10000\fR.
.Sp
The tool prints a warning and continues if a variable cannot be set.
.IP "\-\-show\-all" 4
.IX Item "--show-all"
type: Hash
.Sp
Show all values for these attributes.
.Sp
By default pt-query-digest only shows as many of an attribute's value that
fit on a single line.  This option allows you to specify attributes for which
all values will be shown (line width is ignored).  This only works for
attributes with string values like user, host, db, etc.  Multiple attributes
can be specified, comma-separated.
.IP "\-\-since" 4
.IX Item "--since"
type: string
.Sp
Parse only queries newer than this value (parse queries since this date).
.Sp
This option allows you to ignore queries older than a certain value and parse
only those queries which are more recent than the value.  The value can be
several types:
.Sp
.Vb 9
\&  * Simple time value N with optional suffix: N[shmd], where
\&    s=seconds, h=hours, m=minutes, d=days (default s if no suffix
\&    given); this is like saying "since N[shmd] ago"
\&  * Full date with optional hours:minutes:seconds:
\&    YYYY\-MM\-DD [HH:MM:SS]
\&  * Short, MySQL\-style date:
\&    YYMMDD [HH:MM:SS]
\&  * Any time expression evaluated by MySQL:
\&    CURRENT_DATE \- INTERVAL 7 DAY
.Ve
.Sp
If you give a MySQL time expression, and you have not also specified a \s-1DSN\s0
for \*(L"\-\-explain\*(R", \*(L"\-\-processlist\*(R", or \*(L"\-\-review\*(R", then you must specify
a \s-1DSN\s0 on the command line so that pt-query-digest can connect to MySQL to
evaluate the expression.
.Sp
The MySQL time expression is wrapped inside a query like
\&\*(L"\s-1SELECT UNIX_TIMESTAMP\s0(<expression>)\*(R", so be sure that the expression is
valid inside this query.  For example, do not use \s-1\fBUNIX_TIMESTAMP\s0()\fR because
\&\s-1UNIX_TIMESTAMP\s0(\s-1\fBUNIX_TIMESTAMP\s0()\fR) returns 0.
.Sp
Events are assumed to be in chronological: older events at the beginning of
the log and newer events at the end of the log.  \*(L"\-\-since\*(R" is strict: it
ignores all queries until one is found that is new enough.  Therefore, if
the query events are not consistently timestamped, some may be ignored which
are actually new enough.
.Sp
See also \*(L"\-\-until\*(R".
.IP "\-\-socket" 4
.IX Item "--socket"
short form: \-S; type: string
.Sp
Socket file to use for connection.
.IP "\-\-timeline" 4
.IX Item "--timeline"
Show a timeline of events.
.Sp
This option makes pt-query-digest print another kind of report: a timeline of
the events.  Each query is still grouped and aggregate into classes according to
\&\*(L"\-\-group\-by\*(R", but then they are printed in chronological order.  The timeline
report prints out the timestamp, interval, count and value of each classes.
.Sp
If all you want is the timeline report, then specify \f(CW\*(C`\-\-no\-report\*(C'\fR to
suppress the default query analysis report.  Otherwise, the timeline report
will be printed at the end before the response-time profile
(see \*(L"\-\-report\-format\*(R" and \*(L"\s-1OUTPUT\*(R"\s0).
.Sp
For example, this:
.Sp
.Vb 1
\&  pt\-query\-digest /path/to/log \-\-group\-by distill \-\-timeline
.Ve
.Sp
will print something like:
.Sp
.Vb 6
\&  # ########################################################
\&  # distill report
\&  # ########################################################
\&  # 2009\-07\-25 11:19:27 1+00:00:01   2 SELECT foo
\&  # 2009\-07\-27 11:19:30      00:01   2 SELECT bar
\&  # 2009\-07\-27 11:30:00 1+06:30:00   2 SELECT foo
.Ve
.IP "\-\-type" 4
.IX Item "--type"
type: Array; default: slowlog
.Sp
The type of input to parse.  The permitted types are
.RS 4
.IP "binlog" 4
.IX Item "binlog"
Parse a binary log file that has first been converted to text using mysqlbinlog.
.Sp
For example:
.Sp
.Vb 1
\&   mysqlbinlog mysql\-bin.000441 > mysql\-bin.000441.txt
\&
\&   pt\-query\-digest \-\-type binlog mysql\-bin.000441.txt
.Ve
.IP "genlog" 4
.IX Item "genlog"
Parse a MySQL general log file.  General logs lack a lot of \*(L"\s-1ATTRIBUTES\*(R"\s0,
notably \f(CW\*(C`Query_time\*(C'\fR.  The default \*(L"\-\-order\-by\*(R" for general logs
changes to \f(CW\*(C`Query_time:cnt\*(C'\fR.
.IP "slowlog" 4
.IX Item "slowlog"
Parse a log file in any variation of MySQL slow log format.
.IP "tcpdump" 4
.IX Item "tcpdump"
Inspect network packets and decode the MySQL client protocol, extracting queries
and responses from it.
.Sp
pt-query-digest does not actually watch the network (i.e. it does \s-1NOT\s0 \*(L"sniff
packets\*(R").  Instead, it's just parsing the output of tcpdump.  You are
responsible for generating this output; pt-query-digest does not do it for you.
Then you send this to pt-query-digest as you would any log file: as files on the
command line or to \s-1STDIN.\s0
.Sp
The parser expects the input to be formatted with the following options: \f(CW\*(C`\-x \-n
\&\-q \-tttt\*(C'\fR.  For example, if you want to capture output from your local machine,
you can do something like the following (the port must come last on FreeBSD):
.Sp
.Vb 3
\&  tcpdump \-s 65535 \-x \-nn \-q \-tttt \-i any \-c 1000 port 3306 \e
\&    > mysql.tcp.txt
\&  pt\-query\-digest \-\-type tcpdump mysql.tcp.txt
.Ve
.Sp
The other tcpdump parameters, such as \-s, \-c, and \-i, are up to you.  Just make
sure the output looks like this (there is a line break in the first line to
avoid man-page problems):
.Sp
.Vb 4
\&  2009\-04\-12 09:50:16.804849 IP 127.0.0.1.42167
\&         > 127.0.0.1.3306: tcp 37
\&      0x0000:  4508 0059 6eb2 4000 4006 cde2 7f00 0001
\&      0x0010:  ....
.Ve
.Sp
Remember tcpdump has a handy \-c option to stop after it captures some number of
packets!  That's very useful for testing your tcpdump command.  Note that
tcpdump can't capture traffic on a Unix socket.  Read
<http://bugs.mysql.com/bug.php?id=31577> if you're confused about this.
.Sp
Devananda Van Der Veen explained on the MySQL Performance Blog how to capture
traffic without dropping packets on busy servers.  Dropped packets cause
pt-query-digest to miss the response to a request, then see the response to a
later request and assign the wrong execution time to the query.  You can change
the filter to something like the following to help capture a subset of the
queries.  (See <http://www.mysqlperformanceblog.com/?p=6092> for details.)
.Sp
.Vb 2
\&  tcpdump \-i any \-s 65535 \-x \-n \-q \-tttt \e
\&     \*(Aqport 3306 and tcp[1] & 7 == 2 and tcp[3] & 7 == 2\*(Aq
.Ve
.Sp
All MySQL servers running on port 3306 are automatically detected in the
tcpdump output.  Therefore, if the tcpdump out contains packets from
multiple servers on port 3306 (for example, 10.0.0.1:3306, 10.0.0.2:3306,
etc.), all packets/queries from all these servers will be analyzed
together as if they were one server.
.Sp
If you're analyzing traffic for a MySQL server that is not running on port
3306, see \*(L"\-\-watch\-server\*(R".
.Sp
Also note that pt-query-digest may fail to report the database for queries
when parsing tcpdump output.  The database is discovered only in the initial
connect events for a new client or when <\s-1USE\s0 db> is executed.  If the tcpdump
output contains neither of these, then pt-query-digest cannot discover the
database.
.Sp
Server-side prepared statements are supported.  SSL-encrypted traffic cannot be
inspected and decoded.
.IP "rawlog" 4
.IX Item "rawlog"
Raw logs are not MySQL logs but simple text files with one \s-1SQL\s0 statement
per line, like:
.Sp
.Vb 4
\&  SELECT c FROM t WHERE id=1
\&  /* Hello, world! */ SELECT * FROM t2 LIMIT 1
\&  INSERT INTO t (a, b) VALUES (\*(Aqfoo\*(Aq, \*(Aqbar\*(Aq)
\&  INSERT INTO t SELECT * FROM monkeys
.Ve
.Sp
Since raw logs do not have any metrics, many options and features of
pt-query-digest do not work with them.
.Sp
One use case for raw logs is ranking queries by count when the only
information available is a list of queries, from polling \f(CW\*(C`SHOW PROCESSLIST\*(C'\fR
for example.
.RE
.RS 4
.RE
.IP "\-\-until" 4
.IX Item "--until"
type: string
.Sp
Parse only queries older than this value (parse queries until this date).
.Sp
This option allows you to ignore queries newer than a certain value and parse
only those queries which are older than the value.  The value can be one of
the same types listed for \*(L"\-\-since\*(R".
.Sp
Unlike \*(L"\-\-since\*(R", \*(L"\-\-until\*(R" is not strict: all queries are parsed until
one has a timestamp that is equal to or greater than \*(L"\-\-until\*(R".  Then
all subsequent queries are ignored.
.IP "\-\-user" 4
.IX Item "--user"
short form: \-u; type: string
.Sp
User for login if not current user.
.IP "\-\-variations" 4
.IX Item "--variations"
type: Array
.Sp
Report the number of variations in these attributes' values.
.Sp
Variations show how many distinct values an attribute had within a class.
The usual value for this option is \f(CW\*(C`arg\*(C'\fR which shows how many distinct queries
were in the class.  This can be useful to determine a query's cacheability.
.Sp
Distinct values are determined by \s-1CRC32\s0 checksums of the attributes' values.
These checksums are reported in the query report for attributes specified by
this option, like:
.Sp
.Vb 1
\&  # arg crc      109 (1/25%), 144 (1/25%)... 2 more
.Ve
.Sp
In that class there were 4 distinct queries.  The checksums of the first two
variations are shown, and each one occurred once (or, 25% of the time).
.Sp
The counts of distinct variations is approximate because only 1,000 variations
are saved.  The mod (%) 1000 of the full \s-1CRC32\s0 checksum is saved, so some
distinct checksums are treated as equal.
.IP "\-\-version" 4
.IX Item "--version"
Show version and exit.
.IP "\-\-[no]version\-check" 4
.IX Item "--[no]version-check"
default: yes
.Sp
Check for the latest version of Percona Toolkit, MySQL, and other programs.
.Sp
This is a standard \*(L"check for updates automatically\*(R" feature, with two
additional features.  First, the tool checks the version of other programs
on the local system in addition to its own version.  For example, it checks
the version of every MySQL server it connects to, Perl, and the Perl module
DBD::mysql.  Second, it checks for and warns about versions with known
problems.  For example, MySQL 5.5.25 had a critical bug and was re-released
as 5.5.25a.
.Sp
Any updates or known problems are printed to \s-1STDOUT\s0 before the tool's normal
output.  This feature should never interfere with the normal operation of the
tool.
.Sp
For more information, visit <https://www.percona.com/version\-check>.
.IP "\-\-watch\-server" 4
.IX Item "--watch-server"
type: string
.Sp
This option tells pt-query-digest which server \s-1IP\s0 address and port (like
\&\*(L"10.0.0.1:3306\*(R") to watch when parsing tcpdump (for \*(L"\-\-type\*(R" tcpdump);
all other servers are ignored.  If you don't specify it,
pt-query-digest watches all servers by looking for any \s-1IP\s0 address using port
3306 or \*(L"mysql\*(R".  If you're watching a server with a non-standard port, this
won't work, so you must specify the \s-1IP\s0 address and port to watch.
.Sp
If you want to watch a mix of servers, some running on standard port 3306
and some running on non-standard ports, you need to create separate
tcpdump outputs for the non-standard port servers and then specify this
option for each.  At present pt-query-digest cannot auto-detect servers on
port 3306 and also be told to watch a server on a non-standard port.
.SH "DSN OPTIONS"
.IX Header "DSN OPTIONS"
These \s-1DSN\s0 options are used to create a \s-1DSN.\s0  Each option is given like
\&\f(CW\*(C`option=value\*(C'\fR.  The options are case-sensitive, so P and p are not the
same option.  There cannot be whitespace before or after the \f(CW\*(C`=\*(C'\fR and
if the value contains whitespace it must be quoted.  \s-1DSN\s0 options are
comma-separated.  See the percona-toolkit manpage for full details.
.IP "\(bu" 4
A
.Sp
dsn: charset; copy: yes
.Sp
Default character set.
.IP "\(bu" 4
D
.Sp
dsn: database; copy: yes
.Sp
Default database to use when connecting to MySQL.
.IP "\(bu" 4
F
.Sp
dsn: mysql_read_default_file; copy: yes
.Sp
Only read default options from the given file.
.IP "\(bu" 4
h
.Sp
dsn: host; copy: yes
.Sp
Connect to host.
.IP "\(bu" 4
p
.Sp
dsn: password; copy: yes
.Sp
Password to use when connecting.
If password contains commas they must be escaped with a backslash: \*(L"exam\e,ple\*(R"
.IP "\(bu" 4
P
.Sp
dsn: port; copy: yes
.Sp
Port number to use for connection.
.IP "\(bu" 4
S
.Sp
dsn: mysql_socket; copy: yes
.Sp
Socket file to use for connection.
.IP "\(bu" 4
t
.Sp
The \*(L"\-\-review\*(R" or \*(L"\-\-history\*(R" table.
.IP "\(bu" 4
u
.Sp
dsn: user; copy: yes
.Sp
User for login if not current user.
.SH "ENVIRONMENT"
.IX Header "ENVIRONMENT"
The environment variable \f(CW\*(C`PTDEBUG\*(C'\fR enables verbose debugging output to \s-1STDERR.\s0
To enable debugging and capture all output to a file, run the tool like:
.PP
.Vb 1
\&   PTDEBUG=1 pt\-query\-digest ... > FILE 2>&1
.Ve
.PP
Be careful: debugging output is voluminous and can generate several megabytes
of output.
.SH "SYSTEM REQUIREMENTS"
.IX Header "SYSTEM REQUIREMENTS"
You need Perl, \s-1DBI,\s0 DBD::mysql, and some core packages that ought to be
installed in any reasonably new version of Perl.
.SH "BUGS"
.IX Header "BUGS"
For a list of known bugs, see <http://www.percona.com/bugs/pt\-query\-digest>.
.PP
Please report bugs at <https://bugs.launchpad.net/percona\-toolkit>.
Include the following information in your bug report:
.IP "\(bu" 4
Complete command-line used to run the tool
.IP "\(bu" 4
Tool \*(L"\-\-version\*(R"
.IP "\(bu" 4
MySQL version of all servers involved
.IP "\(bu" 4
Output from the tool including \s-1STDERR\s0
.IP "\(bu" 4
Input files (log/dump/config files, etc.)
.PP
If possible, include debugging output by running the tool with \f(CW\*(C`PTDEBUG\*(C'\fR;
see \*(L"\s-1ENVIRONMENT\*(R"\s0.
.SH "DOWNLOADING"
.IX Header "DOWNLOADING"
Visit <http://www.percona.com/software/percona\-toolkit/> to download the
latest release of Percona Toolkit.  Or, get the latest release from the
command line:
.PP
.Vb 1
\&   wget percona.com/get/percona\-toolkit.tar.gz
\&
\&   wget percona.com/get/percona\-toolkit.rpm
\&
\&   wget percona.com/get/percona\-toolkit.deb
.Ve
.PP
You can also get individual tools from the latest release:
.PP
.Vb 1
\&   wget percona.com/get/TOOL
.Ve
.PP
Replace \f(CW\*(C`TOOL\*(C'\fR with the name of any tool.
.SH "ATTRIBUTES REFERENCE"
.IX Header "ATTRIBUTES REFERENCE"
Events may have the following attributes.  If writing a \*(L"\-\-filter\*(R",
be sure to check that an attribute is defined in each event before
using it, else the filter code may crash the tool with a
\&\*(L"use of uninitialized value\*(R" error.
.PP
You can dump event attributes for any input like:
.PP
.Vb 5
\&  $ pt\-query\-digest                  \e
\&      slow.log                       \e
\&      \-\-filter \*(Aqprint Dumper $event\*(Aq \e
\&      \-\-no\-report                    \e
\&      \-\-sample 1
.Ve
.PP
That will produce a lot of output with \*(L"attribute => value\*(R" pairs like:
.PP
.Vb 10
\&   $VAR1 = {
\&     Query_time => \*(Aq0.033384\*(Aq,
\&     Rows_examined => \*(Aq0\*(Aq,
\&     Rows_sent => \*(Aq0\*(Aq,
\&     Thread_id => \*(Aq10\*(Aq,
\&     Tmp_table => \*(AqNo\*(Aq,
\&     Tmp_table_on_disk => \*(AqNo\*(Aq,
\&     arg => \*(AqSELECT col FROM tbl WHERE id=5\*(Aq,
\&     bytes => 103,
\&     cmd => \*(AqQuery\*(Aq,
\&     db => \*(Aqdb1\*(Aq,
\&     fingerprint => \*(Aqselect col from tbl where id=?\*(Aq,
\&     host => \*(Aq\*(Aq,
\&     pos_in_log => 1334,
\&     ts => \*(Aq071218 11:48:27\*(Aq,
\&     user => \*(Aq[SQL_SLAVE]\*(Aq
\&   };
.Ve
.SS "\s-1COMMON\s0"
.IX Subsection "COMMON"
These attribute are common to all input \*(L"\-\-type\*(R" and \*(L"\-\-processlist\*(R",
except where noted.
.IP "arg" 4
.IX Item "arg"
The query text, or the command for admin commands like \f(CW\*(C`Ping\*(C'\fR.
.IP "bytes" 4
.IX Item "bytes"
The byte length of the \f(CW\*(C`arg\*(C'\fR.
.IP "cmd" 4
.IX Item "cmd"
\&\*(L"Query\*(R" or \*(L"Admin\*(R".
.IP "db" 4
.IX Item "db"
The current database.  The value comes from \s-1USE\s0 database statements.  
By default, \f(CW\*(C`Schema\*(C'\fR is an alias which is automatically
changed to \f(CW\*(C`db\*(C'\fR; see \*(L"\-\-attribute\-aliases\*(R".
.IP "fingerprint" 4
.IX Item "fingerprint"
An abstracted form of the query.  See \*(L"\s-1FINGERPRINTS\*(R"\s0.
.IP "host" 4
.IX Item "host"
Client host which executed the query.
.IP "pos_in_log" 4
.IX Item "pos_in_log"
The byte offset of the event in the log or tcpdump,
except for \*(L"\-\-processlist\*(R".
.IP "Query_time" 4
.IX Item "Query_time"
The total time the query took, including lock time.
.IP "ts" 4
.IX Item "ts"
The timestamp of when the query ended.
.SS "\s-1SLOW, GENERAL, AND BINARY LOGS\s0"
.IX Subsection "SLOW, GENERAL, AND BINARY LOGS"
Events have all available attributes from the log file.  Therefore, you only
need to look at the log file to see which events are available, but remember:
not all events have the same attributes.
.PP
Percona Server adds many attributes to the slow log; see
http://www.percona.com/docs/wiki/patches:slow_extended for more information.
.SS "\s-1TCPDUMP\s0"
.IX Subsection "TCPDUMP"
These attributes are available when parsing \*(L"\-\-type\*(R" tcpdump.
.IP "Error_no" 4
.IX Item "Error_no"
The MySQL error number if the query caused an error.
.IP "ip" 4
.IX Item "ip"
The client's \s-1IP\s0 address.  Certain log files may also contain this attribute.
.IP "No_good_index_used" 4
.IX Item "No_good_index_used"
Yes or No if no good index existed for the query (flag set by server).
.IP "No_index_used" 4
.IX Item "No_index_used"
Yes or No if the query did not use any index (flag set by server).
.IP "port" 4
.IX Item "port"
The client's port number.
.IP "Warning_count" 4
.IX Item "Warning_count"
The number of warnings, as otherwise shown by \f(CW\*(C`SHOW WARNINGS\*(C'\fR.
.SS "\s-1PROCESSLIST\s0"
.IX Subsection "PROCESSLIST"
If using \*(L"\-\-processlist\*(R", an \f(CW\*(C`id\*(C'\fR attribute is available for
the process \s-1ID,\s0 in addition to the common attributes.
.SH "AUTHORS"
.IX Header "AUTHORS"
Baron Schwartz, Daniel Nichter, and Brian Fraser
.SH "ABOUT PERCONA TOOLKIT"
.IX Header "ABOUT PERCONA TOOLKIT"
This tool is part of Percona Toolkit, a collection of advanced command-line
tools for MySQL developed by Percona.  Percona Toolkit was forked from two
projects in June, 2011: Maatkit and Aspersa.  Those projects were created by
Baron Schwartz and primarily developed by him and Daniel Nichter.  Visit
<http://www.percona.com/software/> to learn about other free, open-source
software from Percona.
.SH "COPYRIGHT, LICENSE, AND WARRANTY"
.IX Header "COPYRIGHT, LICENSE, AND WARRANTY"
This program is copyright 2008\-2016 Percona \s-1LLC\s0 and/or its affiliates.
.PP
\&\s-1THIS PROGRAM IS PROVIDED \*(L"AS IS\*(R" AND WITHOUT ANY EXPRESS OR IMPLIED
WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.\s0
.PP
This program is free software; you can redistribute it and/or modify it under
the terms of the \s-1GNU\s0 General Public License as published by the Free Software
Foundation, version 2; \s-1OR\s0 the Perl Artistic License.  On \s-1UNIX\s0 and similar
systems, you can issue `man perlgpl' or `man perlartistic' to read these
licenses.
.PP
You should have received a copy of the \s-1GNU\s0 General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, \s-1MA\s0  02111\-1307  \s-1USA.\s0
.SH "VERSION"
.IX Header "VERSION"
pt-query-digest 2.2.17
